\chapter{Introduction}
In this thesis, we propose and analyze some new linearly stabilized schemes for the time integration of stiff nonlinear PDEs. A linearly stabilized scheme of first order has been used in a number of areas, with the first known example being from a paper by Douglas and Dupont \cite{douglas1971alternating} where this technique was used for the solution to a variable coefficient heat equation on rectangular domains. In subsequent years, the idea has been rediscovered by Smereka \cite{smereka2003semi}, and  Eyre \cite{eyre1998bunconditionally}, who first used the name ``linearly stabilized''. Others have gone on to find application of these schemes to Hele-Shaw flow, interface motion, image processing, and solving PDEs on surfaces \cite{eyre1998bunconditionally,salac2008local,glasner2002diffuse,schonlieb2011unconditionally,macdonald2009implicit}.

In each of the references mentioned in the previous paragraph, the authors have succeeded in implementing only a first order time stepping method. Recently in \cite{duchemin2014explicit},  Duchemin and Eggers consolidated the approach and produced a second order linearly stabilized scheme they refer to as the explicit-implicit-null (EIN) method. Their method attains second order accuracy by extrapolating the first order results. Moreover, they identified that the key principle for the success of any linearly stabilized scheme is unconditional stability. Indeed, a significant section of their paper is devoted to showing that their method is unconditionally stable under only a mild condition on a parameter that is introduced.

Our derivations for new linearly stabilized schemes also begins by ensuring that the newly derived schemes are in fact unconditionally stable. The techniques we employ in our stability analysis are very much those of a standard linear stability analysis and are reviewed first. A brief discussion of order of accuracy and Richardson extrapolation is also included before an overview of the thesis is given.

\section{Linear Stability Analysis}
\subsection{Stability and the scalar test equation}
Linear stability analysis is a method of analysis predicated on requiring that the numerical solution replicates properties inherent in the exact solution to the test equation,
% Linear stability analysis is predicated finding the constraints necessary on the time step-size so that the numerical solution generated using that particular time stepping method applied to the test equation, 
\begin{align}
u' = \lambda u, 
\quad \lambda < 0.
\label{test eqn}
\end{align}  
% has properties resembling that of the exact solution to the test equation,
Over one time step, the exact solution is 
\begin{align}
u(t^n + \Delta t) = e^{\lambda \Delta t} u(t^n).
\end{align}
Observe that, in general, the exact solution satisfies
\begin{align}
\frac{\abs{u(t^n + \Delta t)}}{\abs{u(t^n)}}
= \abs{e^{\lambda\Delta t} } 
< 1,
\quad\text{for all } \lambda\Delta t < 0.
\end{align}
The analogous property for numerical methods is what we will refer to as linear stability.

For example, applying the forward Euler method to the test equation \cref{test eqn}, yields
\begin{align}
\frac{u^{n+1} - u^n}{\Delta t} = \lambda u^n 
\iff u^{n+1} = \underbrace{(1 + \lambda \Delta t)}_{=\xi_{FE}} u^n, 
\end{align}
where $u^n$ is an approximation to $u(t^n)$. Then imposing $\abs{\xi_{FE}} < 1$, we get 
\begin{align}
\abs{1+ \lambda\Delta t} < 1 
\iff -2 < \lambda\Delta t < 0,
\end{align}
which implies that, $\Delta t < 2/\abs{\lambda}$ must be satisfied for stability. As the time step-size, $\Delta t$, is constrained, we say forward Euler is conditionally stable. 

As another example, we may apply backward Euler to the test equation. This yields
\begin{align}
\frac{u^{n+1} - u^n}{\Delta t} = \lambda u^{n+1} 
\iff 
u^{n+1} = \underbrace{\frac{1}{1 - \lambda\Delta t}}_{=\xi_{BE}} u^n.
\end{align}
This time, imposing $\abs{\xi_{BE}}<1$ adds no new constraint to the time step-size. When no additional constraints are imposed on the time step-size, we say the numerical method is unconditionally stable.

More generally, to determine the stability constraint of any one-step method, we apply the method to the test equation, rearrange as $u^{n+1} = \xi(\lambda\Delta t) u^n$, and impose $\abs{\xi(\lambda\Delta t)} < 1$. The quantity $\xi(\lambda\Delta t)$ is commonly referred to as the amplification factor, and the region, $\{\lambda\Delta t \in \bC \mid \abs{\xi(\lambda\Delta t)} < 1\}$, the stability region. In other words, for stability, we require that the magnitude of the amplification factor is less than one.
 
\subsection{Stability contours}
A stability contour plot is a graphical device for understanding the stability constraint of a method. It offers a way for us to verify calculations done analytically, or to visualize the stability region of a numerical method where an analytic solution is infeasible. Stability contour plots in this thesis all show contours of the amplification factor $\xi(\lambda\Delta t)$ plotted over a subset of the region $\{\lambda\Delta t \in \bC \mid \Im(\lambda\Delta t) \geq 0\}$, with a focus on the left half plane and the negative real line. \cref{fig:FE BE stab cont} shows stability contours of the forward Euler and the backward Euler method. Note that the regions are symmetric with respect to the real axis and thus only $\Im(\lambda\Delta t) \geq 0$ will be plotted.

\begin{figure}[htb!]
	\centering
\begin{minipage}{0.45\textwidth}
\includegraphics[width=0.95\textwidth]{fe_stab}
\end{minipage}
\begin{minipage}{0.45\textwidth}
\includegraphics[width=0.95\textwidth]{be_stab}
\end{minipage}
\caption[Examples of stability contour plots.]{On the left is the stability contour plot for forward Euler. The stability region is the interior of the 1-contour. On the right is the stability contour plot for backward Euler. The stability region is the region outside the 1-contour.}
\label{fig:FE BE stab cont}
\end{figure}

\subsection{Relation to stiff PDEs}
Recall that our motivation is to develop methods suited to the time integration of stiff nonlinear PDEs. So how does the time step restriction of a numerical method derived from application to the test equation relate to time step selection for a stiff nonlinear PDE? The relation is as follows. Suppose the PDE has been discretized in space and we are to advance the solution of the resulting large system of ODEs, $u' = F(u)$, by one time step, i.e.\ advance the numerical solution $u^n$ to $u^{n+1}$. Over just one time step, it may be reasonable to consider the linearization, 
\begin{align*}
        u' = \bar u + \pd{F}{u} \bigg|_{u=\bar u} (u-\bar u)
= \bar u + A(u-\bar u), 
\end{align*}
or setting $v=u-\bar u$, $v' = Av$. Further assuming that $A$ is diagonalizable, $A=T^{-1}DT$, where $D=\diag(\lambda_1,\dots,\lambda_N)$, we get 
\begin{align}
        v' = T^{-1}DTv 
&\iff (Tv)' = D(Tv)
\\&\iff (Tv)_k' = \lambda (Tv)_k, \quad k=1,\dots, N.
\end{align}
In other words, under appropriate conditions, it may be fair to analyze the dynamics of the nonlinear system by inspecting the eigenvalues of the Jacobian from its linearized state. We therefore require that the computation is stable for each eigenmode. The time step constraint will then be dictated by the largest absolute eigenvalue.

For instance, suppose we found, from a linearized system of ODEs, the eigenvalues to be $2(\cos(k\Delta x) -1)/\Delta x^2$, $k=1,\dots,N$. Then the largest absolute eigenvalue can be bounded as 
\begin{align}
    \abs{\frac{2}{\Delta x^2}(\cos(k\Delta x) -1)} \leq \frac{4}{\Delta x^2},
\end{align}
and stable time step-sizes for forward Euler must then satisfy $\Delta t < \Delta x^2/4$. On the other hand, unconditionally stable methods such as backward Euler, maintain stability irrespective of the grid size $\Delta x$.

That unconditionally stable methods maintain stability irrespective of the grid size is crucial for the solution to stiff problems. In \cref{chap:num experiments}, we will solve problems in 2D and 3D where the largest absolute eigenvalues scale like $\O(h^2)$ and $\O(h^4)$, where $h$ is the spatial grid size. In those cases, a conditionally stable method such as forward Euler requires $\Delta t = \O(h^k)$, $k= 2$ or $4$, and would give unnecessarily fine temporal resolution.  More critically, this would greatly increase the cost of computation, or else, to combat this deficiency, have low spatial resolution.

\section{Order of Accuracy}
If two competing numerical methods, consume similar levels of resources (e.g., CPU time, or memory) but one gives more accurate approximations, then likely it would be deemed superior to the other. 

For a time stepping method applied to the initial value problem 
\begin{align}
\begin{cases}
        u' = F(u), & 0\leq t \leq T, \\
 u(0) = u_0, 
\end{cases}
\end{align}
with step-size $\Delta t$, 
we will say that the method is convergent of order $k$ (or $k$th order accurate) if the global error behaves as 
\begin{align}
        \norm{u^{n} - u(t^n)} = \O(\Delta t^k),
\quad\text{as}\quad \Delta t \to 0.
\end{align}

This points to a preference for high order accurate methods. Intuitively, in order to achieve some desired level of accuracy, a low order method will require a finer time step-size than a method of higher order accuracy. Then if each time step had comparable costs, the higher order method will require less resources overall to compute the solution. 

Finally, we note that familiar methods such as forward Euler and backward Euler are first order accurate.

\subsection{Richardson extrapolation}
One of the methods under consideration relies on Richardson extrapolation, so we include here a brief note on this technique. A comprehensive text discussing the validity of this technique can be found in \cite{sidi2003practical}.

Suppose we are approximating some quantity, $q$, via a rule $\bar q$ that is dependent on the step-size $h$ and that the error is of the form 
\begin{align}
        q - \bar q(h) = C_1 h^k  + C_2 h^{k+1} + \cdots.
\end{align}
Observe that if we evaluate both $\bar q(h)$ and $\bar q(h/2)$, then we can eliminate the leading order error term,
\begin{align}
        q-q^*(h) = q-\frac{2^k \bar q(h/2)  -\bar q(h)}{2^k-1} 
= Ch^{k+1} + \cdots ,
\end{align}
to achieve higher order accuracy.

\section{Overview}
In Chapter 2, we formally introduce the notion of linear stabilization. Motivation for this technique is supplied by the need to handle a 1D stiff nonlinear PDE describing axisymmetric mean curvature flow and leads us to the well-known first order linearly stabilized time integrator and the EIN method of Duchemin and Eggers. Following that, the framework in which we analyze the stability of linearly stabilized schemes is set. 

In Chapter 3 we investigate implicit-explicit (IMEX) linear multistep methods within the linear stabilization framework. A detailed comparison of the schemes based on IMEX multistep schemes and the EIN method is conducted. Our experiments suggest criteria in addition to unconditional stability are necessary for practical linearly stabilized schemes. This in turn eliminates third and higher order multistep-based linearly stabilized schemes from use. 

In Chapter 4, we explore the use of exponential Runge-Kutta methods to mend this deficiency. A second order and a fourth order exponential Runge-Kutta method are verified to exhibit unconditional stability over an unbounded parameter range. (Coming back to this after I have chapter 4 written)

In Chapter 5, application of our linearly stabilized schemes to a number of 2D and 3D problems are presented. Not surprisingly, our second order schemes offer improvements over the commonly used first order linearly stabilized scheme. The experiments show that our schemes provide substantial efficiency improvement yet the complexity of its implementation is no greater than solving a heat equation with standard implicit methods.

Finally, some concluding remarks are presented in Chapter 6.  
 