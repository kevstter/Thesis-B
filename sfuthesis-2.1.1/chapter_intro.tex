\chapter{Introduction}
In this thesis, we propose and analyze some new linearly stabilized schemes for the time integration of stiff nonlinear PDEs. A linearly stabilized scheme of first order has been used in a number of areas, with the first known example being from a paper by Douglas and Dupont \cite{douglas1971alternating} where they use this technique for the solution to a variable coefficient heat equation on rectangular domains. In subsequent years, the idea has been rediscovered by others \cite{eyre1998unconditionally,smereka2003semi} and has found applications to gradient systems, Hele-Shaw flow, interface motion, image processing, and solving PDEs on surfaces \cite{eyre1998bunconditionally,salac2008local,glasner2002diffuse,schonlieb2011unconditionally,macdonald2009implicit}.

In each of the references mentioned in the previous paragraph, the authors have succeeded in implemented only a first order time stepping method. Recently in \cite{duchemin2014explicit},  Duchemin and Eggers consolidated the approach and produced a second order linearly stabilized scheme they refer to as the explicit-implicit-null (EIN) method. The procedure they propose works off the first order scheme and extrapolates to second order. Moreover, they identified that the key principle for the success of any linearly stabilized scheme is unconditional stability. Indeed, a significant section of their paper is devoted to showing that their method is unconditionally stable under only a mild condition on a parameter that is introduced.

Our derivations for new linearly stabilized schemes also begins by ensuring that the newly derived schemes are in fact unconditionally stable. The techniques we employ in our stability analysis are very much those of a standard linear stability analysis and are reviewed first. A brief discussion of order of accuracy and error constants is also included. 

\section{Linear Stability Analysis}
\subsection{Stability and the scalar test equation}
Linear stability analysis is predicated finding the constraints necessary on the time step-size so that the numerical solution generated using that particular time stepping method applied to the test equation, 
\begin{align}
u' = \lambda u, 
\quad \lambda < 0,
\label{test eqn}
\end{align}  
has properties resembling that of the exact solution to the test equation,
\begin{align}
u(t^n + \Delta t) = e^{\lambda \Delta t} u(t^n).
\end{align}
Observe that, in general, the exact solution satisfies
\begin{align}
\frac{\abs{u(t^n + \Delta t)}}{\abs{u(t^n)}}
= \abs{e^{\lambda\Delta t} } 
< 1,
\quad\text{for all } \Delta t > 0.
\end{align}
The analogous property for numerical methods is what we will refer to as stability.

For example, applying the forward Euler method to the test equation \cref{test eqn}, we get 
\begin{align}
\frac{u^{n+1} - u^n}{\Delta t} = \lambda u^n 
\iff u^{n+1} = \underbrace{(1 + \lambda \Delta t)}_{=\xi_{FE}} u^n, 
\end{align}
where $u^n$ is an approximation to $u(t^n)$. Then imposing $\abs{\xi_{FE}} < 1$, we get 
\begin{align}
\abs{1+ \lambda\Delta t} < 1 
\iff -2 < \lambda\Delta t < 0,
\end{align}
and so for stability, $\Delta t < -2/\lambda$ must be satisfied. As the time step-size, $\Delta t$, is constrained, we say forward Euler is conditionally stable. 

For another example, we may apply backward Euler to the test equation. Doing so we get 
\begin{align}
\frac{u^{n+1} - u^n}{\Delta t} = \lambda u^{n+1} 
\iff 
u^{n+1} = \underbrace{\frac{1}{1 - \lambda\Delta t}}_{=\xi_{BE}} u^n.
\end{align}
This time, imposing $\abs{\xi_{BE}}<1$ adds no new constraint to the time step-size. When no additional constraints are imposed on the time step-size, we say the numerical method is unconditionally stable.

More generally, to determine the stability constraint of any one step method, one applies said method to the test equation, rearranges as $u^{n+1} = \xi(\lambda\Delta t) u^n$, and imposes $\abs{\xi(\lambda\Delta t)} < 1$. The quantity $\xi(\lambda\Delta t)$ is commonly referred to as the amplification factor and the region where $\abs{\xi(\lambda\Delta t)} < 1$ the stability region (of the numerical method.) In other words, for stability, we require that the magnitude of the amplification factor is less than one.
 
\subsection{Stability contours}
A stability contour plot is a graphical device for understanding the stability constraint of a method. It offers a way for us to verify calculations done analytically, or to visualize the stability region of a numerical method where an analytic solution is infeasible. Stability contours plots in this thesis all show contours of the amplification factor $\xi(\lambda\Delta t)$ plotted over a subset of the region $\{\lambda\Delta t \in \bC \mid \Delta t > 0\}$, with a focus on the left half plane and in particular the negative real line. \cref{fig:FE BE stab cont} shows stability contours of the forward Euler and the backward Euler method. Note that the regions are symmetric with respect to the real axis and thus only $\Im(\lambda\Delta t) \geq 0$ will be plotted.

\begin{figure}[htb!]
	\centering
\begin{minipage}{0.45\textwidth}
\includegraphics[width=0.95\textwidth]{fe_stab}
\end{minipage}
\begin{minipage}{0.45\textwidth}
\includegraphics[width=0.95\textwidth]{be_stab}
\end{minipage}
\caption[Examples of stability contour plots.]{On the left is the stability contour plot for forward Euler. The stability region is the interior of the 1-contour. On the right is the stability contour plot for backward Euler. The stabilty region is the region outside the 1-contour.}
\label{fig:FE BE stab cont}
\end{figure}

\subsection{Relation to stiff PDEs}
Recall that our motivation is to develop methods suited to the time integration of stiff nonlinear PDEs. So how does the time step restriction of a numerical method derived from application to the test equation relate to time step selection for a stiff nonlinear PDE? The relation is as follows. Suppose the PDE has been discretized in space and we are to advance the solution of the resulting large system of ODEs, $u' = \N(u)$, by one time step, i.e.\ advance the numerical solution $u^n$ to $u^{n+1}$. Over just one time step, it may be reasonable to consider the linearization, 
\begin{align*}
        u' = \bar u + \pd{\N}{u} \bigg|_{u=\bar u} (u-\bar u), 
\end{align*}
or setting $v=u-\bar u$, $v' = Av$. Further assuming that $A$ is diagonalizable, $A=T^{-1}DT$, where $D=\diag(\lambda_1,\dots,\lambda_N)$, we get 
\begin{align}
        v' = T^{-1}DTv 
&\iff (Tv)' = D(Tv)
\\&\iff w_k' = \lambda w_k, \quad k=1,\dots, N.
\end{align}
In other words, under appropriate conditions, it may be fair to analyze the dynamics of the nonlinear system by inspecting the eigenvalues of the Jacobian from its linearized state. Thus to time step, we require that the computation be stable for each eigenmode. The time step constraint will then be dictated by the largest absolute eigenvalue.

For instance, suppose we found, from a linearized system of ODEs, the eigenvalues to be $2(\cos(k\Delta x) -1)/\Delta x^2$. Then the largest absolute eigenvalue can be bounded as 
\begin{align}
    \abs{\frac{2}{\Delta x^2}(\cos(k\Delta x) -1)} \leq \frac{4}{\Delta x^2},
\end{align}
and stable time step-sizes for forward Euler must then satisfy $\Delta t < \Delta x^2/4$. On the other hand, unconditionally stable methods such as backward Euler, maintain stability irrespective of the grid size $\Delta x$.

That unconditionally stable methods maintain stability irrespective of the grid size is crucial for the solution to stiff problems. In \cref{chap:num experiments}, we will solve problems in 2D and 3D where the largest absolute eigenvalues scale like $\O(h^2)$ and $\O(h^4)$, where $h$ is the spatial grid size. In those cases, a conditionally stable method requiring $\Delta t = \O(h^k)$, $k\geq 2$, would give unnecessarily fine temporal resolution, and more critically, either push the cost of the computation to absurd levels, or else be forced to resolve poorly in space.

\section{Accuracy}
\subsection{Order of accuracy}

\subsection{Richardon extrapolation}

\section{Overview}
This is then followed by Chapter 2 where we formally introduce the notion of linear stabilization. Movitation for this technique is supplied by the need to handled a 1D stiff nonlinear PDE describing axisymmetric mean curvature flow and leads us to the well-known first order linearly stabilized time integrator and the EIN method of Duchemin and Eggers. Following that, the framework in which we analyze the stability of linearly stabilized schemes is set. 

In Chapter 3 we investigate implicit-explicit (IMEX) linear multistep methods within the linear stabilization framework. A detailed comparison of the schemes based on IMEX multistep schemes and the EIN method is conducted. Our experiments suggest criteria in addition to unconditional stability are necessary for practical linearly stabilized schemes. This in turn eliminates third order and higher multistep based linearly stabilized schemes from use. 

In Chapter 4, we explore the use of exponential Runge-Kutta methods to mend this deficiency. A second order and a fourth order exponential Runge-Kutta method are verified to exhibit parameter restrictions of the right form. However, other complications limits their use.

In Chapter 5, application of our linearly stabilized schemes to a number of 2D and 3D problems are presented. Not surprisingly, our second order schemes offer massive improvements over the commonly used first order linearly stabilized scheme. The experiments show that our schemes provide substantial efficiency improvement yet can be implemented with tremendous ease. 

Finally, some concluding remarks are presented in Chapter 6.  
 